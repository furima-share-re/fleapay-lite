# LLMæŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼

æ±ç”¨çš„ã§æ‹¡å¼µæ€§ã®é«˜ã„LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã™ã€‚è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOpenAIã€Anthropicã€Google Geminiãªã©ï¼‰ã‚’çµ±ä¸€çš„ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æ‰±ãˆã¾ã™ã€‚

## ğŸ¯ ç‰¹å¾´

- **æ±ç”¨æ€§**: è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¯¾å¿œ
- **æ‹¡å¼µæ€§**: æ–°ã—ã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ç°¡å˜ã«è¿½åŠ å¯èƒ½
- **ç‰¹æ€§ã®æ´»ç”¨**: å„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ç‹¬è‡ªæ©Ÿèƒ½ã‚‚ä½¿ç”¨å¯èƒ½
- **å¾Œæ–¹äº’æ›æ€§**: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‚’å£Šã•ãšæ®µéšçš„ã«ç§»è¡Œå¯èƒ½
- **å‹å®‰å…¨**: TypeScriptã§å®Œå…¨ã«å‹ä»˜ã‘

## ğŸ“¦ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```typescript
import { chatCompletion, imageEdit } from '@/lib/llm';

// ãƒãƒ£ãƒƒãƒˆå®Œäº†ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼‰
const response = await chatCompletion({
  model: 'gpt-4o',
  messages: [
    { role: 'user', content: 'Hello, world!' }
  ],
  max_tokens: 100,
});

console.log(response.content);

// ç”»åƒç·¨é›†
const imageResponse = await imageEdit({
  model: 'dall-e-2',
  image: imageFile,
  prompt: 'Add a beautiful frame',
});
```

### ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š

```typescript
import { getLLMProvider } from '@/lib/llm';

// ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: openaiï¼‰
const provider = getLLMProvider();

// æ˜ç¤ºçš„ã«æŒ‡å®š
const openaiProvider = getLLMProvider('openai');
// const anthropicProvider = getLLMProvider('anthropic'); // å°†æ¥è¿½åŠ 
```

### ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨

```typescript
import { getLLMProvider } from '@/lib/llm';

const provider = getLLMProvider('openai');
if (provider) {
  // å…±é€šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çµŒç”±
  const response = await provider.chatCompletion({ ... });
  
  // ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®æ©Ÿèƒ½ã«ã‚¢ã‚¯ã‚»ã‚¹
  const nativeClient = provider.getNativeClient<OpenAI>();
  if (nativeClient) {
    // OpenAI SDKã®å…¨æ©Ÿèƒ½ã‚’ä½¿ç”¨å¯èƒ½
    const stream = await nativeClient.chat.completions.create({
      stream: true,
      // ...
    });
  }
}
```

## ğŸ”§ ç’°å¢ƒå¤‰æ•°

```bash
# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: openaiï¼‰
LLM_PROVIDER=openai

# OpenAIè¨­å®šï¼ˆæ—¢å­˜ï¼‰
OPENAI_API_KEY=sk-...
HELICONE_API_KEY=sk-...

# å°†æ¥è¿½åŠ ã™ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
# ANTHROPIC_API_KEY=sk-...
# GEMINI_API_KEY=...
```

## ğŸš€ æ–°ã—ã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¿½åŠ æ–¹æ³•

### 1. ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ

`lib/llm/providers/anthropic.ts`:

```typescript
import type { LLMProviderInterface, ChatCompletionOptions, ChatCompletionResponse } from '../types';
import Anthropic from '@anthropic-ai/sdk';

export class AnthropicProvider implements LLMProviderInterface {
  readonly name = 'anthropic' as const;
  private client: Anthropic | null;

  constructor() {
    const apiKey = process.env.ANTHROPIC_API_KEY;
    this.client = apiKey ? new Anthropic({ apiKey }) : null;
  }

  isAvailable(): boolean {
    return this.client !== null;
  }

  async chatCompletion(options: ChatCompletionOptions): Promise<ChatCompletionResponse> {
    if (!this.client) throw new Error('Anthropic client not available');
    
    // Anthropic APIå‘¼ã³å‡ºã—
    const response = await this.client.messages.create({
      model: options.model,
      messages: options.messages.map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: typeof msg.content === 'string' ? msg.content : msg.content[0].text,
      })),
      max_tokens: options.max_tokens || 1024,
    });

    return {
      content: response.content[0].text,
      model: response.model,
      usage: {
        input_tokens: response.usage.input_tokens,
        output_tokens: response.usage.output_tokens,
      },
      raw: response,
    };
  }

  getNativeClient(): Anthropic | null {
    return this.client;
  }
}
```

### 2. ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã«ç™»éŒ²

`lib/llm/factory.ts`:

```typescript
import { AnthropicProvider } from './providers/anthropic';

function createProvider(provider: LLMProvider): LLMProviderInterface | null {
  switch (provider) {
    case 'openai':
      return new OpenAIProvider();
    case 'anthropic':  // è¿½åŠ 
      return new AnthropicProvider();
    // ...
  }
}
```

### 3. å‹å®šç¾©ã«è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

`lib/llm/types.ts`:

```typescript
export type LLMProvider = 'openai' | 'anthropic' | 'gemini' | ...;
```

## ğŸ“ æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®ç§»è¡Œ

### Before (æ—¢å­˜ã‚³ãƒ¼ãƒ‰)

```typescript
import { openai, isOpenAIAvailable } from '@/lib/openai';

if (!isOpenAIAvailable()) {
  return NextResponse.json({ error: 'not_configured' }, { status: 503 });
}

const response = await openai!.chat.completions.create({
  model: 'gpt-4o',
  messages: [{ role: 'user', content: 'Hello' }],
});
```

### After (æ–°API)

```typescript
import { chatCompletion } from '@/lib/llm';

try {
  const response = await chatCompletion({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: 'Hello' }],
  });
  console.log(response.content);
} catch (error) {
  // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
}
```

## ğŸ¨ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç‰¹æ€§ã«å¿œã˜ãŸä½¿ã„åˆ†ã‘

### ã‚¿ã‚¹ã‚¯åˆ¥ã®æ¨å¥¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

```typescript
// ç”»åƒè§£æï¼ˆGPT-4oæ¨å¥¨ï¼‰
const imageAnalysis = await chatCompletion({
  model: 'gpt-4o',
  messages: [{ role: 'user', content: [{ type: 'image_url', ... }] }],
});

// é•·æ–‡å‡¦ç†ï¼ˆClaudeæ¨å¥¨ï¼‰
const longText = await chatCompletion({
  model: 'claude-3-opus',
  messages: [{ role: 'user', content: veryLongText }],
});

// ã‚³ã‚¹ãƒˆé‡è¦–ï¼ˆGeminiæ¨å¥¨ï¼‰
const cheap = await chatCompletion({
  model: 'gemini-pro',
  messages: [{ role: 'user', content: 'Hello' }],
});
```

## ğŸ“š APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### `chatCompletion(options)`

ãƒãƒ£ãƒƒãƒˆå®Œäº†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `model`: ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: `'gpt-4o'`, `'claude-3-opus'`ï¼‰
- `messages`: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—
- `temperature?`: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0-2ï¼‰
- `max_tokens?`: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- `response_format?`: ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ï¼ˆ`{ type: 'json_object' }`ãªã©ï¼‰

**æˆ»ã‚Šå€¤:**
```typescript
{
  content: string;
  model: string;
  usage?: { prompt_tokens?: number; completion_tokens?: number; total_tokens?: number };
  raw?: unknown; // ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
}
```

### `imageEdit(options)`

ç”»åƒç·¨é›†ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆå¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã¿ï¼‰ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `model`: ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: `'dall-e-2'`ï¼‰
- `image`: Fileã¾ãŸã¯Buffer
- `prompt`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
- `size?`: ç”»åƒã‚µã‚¤ã‚ºï¼ˆä¾‹: `'1024x1024'`ï¼‰

**æˆ»ã‚Šå€¤:**
```typescript
{
  image: Buffer; // base64ãƒ‡ã‚³ãƒ¼ãƒ‰æ¸ˆã¿
  model: string;
  raw?: unknown;
}
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨ã§ããªã„

```typescript
const provider = getLLMProvider('anthropic');
if (!provider) {
  console.error('Anthropic provider is not available. Check ANTHROPIC_API_KEY.');
}
```

### ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹

```typescript
const provider = getLLMProvider('openai');
const nativeClient = provider?.getNativeClient<OpenAI>();
if (nativeClient) {
  // OpenAI SDKã®å…¨æ©Ÿèƒ½ã‚’ä½¿ç”¨
}
```

## ğŸ“ æ³¨æ„äº‹é …

- æ—¢å­˜ã®`lib/openai.ts`ã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã—ã¦ã„ã¾ã™ãŒã€æ–°è¦ã‚³ãƒ¼ãƒ‰ã§ã¯`lib/llm`ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ©Ÿèƒ½ãŒç•°ãªã‚Šã¾ã™ï¼ˆ`imageEdit`ãªã©ï¼‰
- Heliconeã¯ç¾åœ¨OpenAIã®ã¿å¯¾å¿œï¼ˆå°†æ¥ä»–ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚‚å¯¾å¿œäºˆå®šï¼‰

